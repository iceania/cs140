          	    +---------------------------+
		    |         CS 140  		|
		    | PROJECT 3: VIRTUAL MEMORY	|
		    |	   DESIGN DOCUMENT  	|
		    +---------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Sam Oluwalana <hhwr85@stanford.edu>
John-Ashton Allen <bglp05@stanford.edu>
Matt Chun-lum <mchunlum@stanford.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			PAGE TABLE MANAGEMENT
			=====================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/* Frame.h */

struct frame_table{
       struct bitmap *used_frames;   /* Bit map that tracks the used frame*/
       struct lock frame_table_lock; /* A lock on that bitmap*/
       void *base;  		     /* Base of the user memory pool*/
       uint32_t size;		     /* Size of the user memory pool in
       page size */
       struct frame _entry *entries; /* Table of frame entries */
} f_table;

struct frame_entry{	
       /* Boolean describing whether this fram is evictable */
       bool is_pinned;		     
       struct thread *cur_owner;      /* Current owner of this frame */
       void *uaddr;   /* user virtual address that is in this frame*/ 
};


/* Process.h */
	
/* The exec_info is a pointer to an array of ELF program
   header information this information is used to determine  
   where on disk the particular missing page is located.
   the information that it stores is for the entire header,
   each header is an entire segment so the size of this
   struct will be less than 5 * sizeof(exec_page_info).
   The only loadable segments right now are the code
   segment and the data segment with the global and static data.*/
   
   struct exec_page_info *exec_info;
   uint32_t num_exec_pages;

   /* A hash table that stores the necessary information to
      map a file into the address space and to lazily load
      the information from the file */
   struct hash mmap_table;
	mapid_t mapid_counter;

	

/* This is the struct that describes the necessary ELF
   program header information that is needed to read
   in the executable on a page fault. It does this by
   taking the faulting addresses most significant 20
   bits and seeing if it is in this particular entries
   bounds (mem_page and end_addr). Then it takes this
   offset from the faulting address and mem_page and
   adds it to the file_offset of the elf file and then
   reads in the appropriate amounts of data by calculating
   the appropriate read_bytes and zero_bytes.
   NOTE: the segment is not constrained to be only one page */

struct exec_page_info{
       /* The starting address in virtual memory of this segment*/
       uint32_t mem_page;
       
       /* The address one byte past the end of this headers segment*/
       uint32_t end_addr;

       /* The offset into the executable file for this particular
       segment*/
       uint32_t file_offset;

       /* The number of bytes to read from this segment*/
       uint32_t read_bytes;

       /* The number of bytes that are zero at the end of this
       segment. MAY BE MORE THAN ONE page worth of zero bytes*/
       uint32_t zero_bytes;  
       
       /* Whether this segment is read/write or read only*/
       bool writable;
};

/* The entry in the mmap table */
struct mmap_hash_entry{
	mapid_t mmap_id;     	/* Key into the hash table*/
	uint32_t begin_addr;	/* start address of this mmapping*/
	
	/* While we can calculate this from the filesize accessing the
	disk In any way is too slow so just keep it stored in memory*/
	uint32_t end_addr;
	
	int fd;		     /* FD for this mapping*/
	uint32_t num_pages;  /* Number of pages so I don't have to calculate*/
	struct hash_elem elem;  /* hash elem*/
};

---- ALGORITHMS ----

>> A2: In a few paragraphs, describe your code for locating the frame,
>> if any, that contains the data of a given page.

When a user process tries to access memory that belongs to them it's present
bit is 1 in it's page table.  In this case, the address of the frame is 
written in the PTE_ADDR bit. When we need to find the frame_entry for a user's
virtual address we simply translate the user address to a kernel address
then we use that kaddr as an offset in the kernel table. The frame_entry
contains the user address that is currently mapped to it, a variable
describing whether it is pinned or not and a condition variable that will
be used to synchronize eviction. The code for locating the frame just uses
offsets from the kaddr passed in. Our frame table implementation manages
all off the memory for a user process, any calls that would have been 
palloc_get_page(PAL_USER) now need to be frame_get_page(PAL_USER) and
calls to palloc_get_page(PAL_USER) will fail because that pool is
completely empty. 


>> A3: How does your code coordinate accessed and dirty bits between
>> kernel and user virtual addresses that alias a single frame, or
>> alternatively how do you avoid the issue?

We choose to use the user's address to dereference memory, because we only
use the user addresses to dereference memory we know that the accessed bits
and the dirty bits will be set by the processor. We also know that on
writing data out to swap and back to disk for memory mapped files we
can use the kernel virtual address in order to keep the accessed and
dirty bits for the user the same regardless of the fault that caused the
frame to be evicted. Using the kernel virtual address to access memory in
the eviction process allows us to ensure that the bits for the user's PTE
entry stay as they were. Because we manage the memory in this way we 


---- SYNCHRONIZATION ----

>> A4: When two user processes both need a new frame at the same time,
>> how are races avoided? 

When a process needs a new frame they fault, then they call
frame_get_frame with the appropriate flags. Inside frame_get_frame we have
a frame table lock must be acquired to get a frame so we know that there
is no race condition in this place. When a user process requires a new
 frame it searches a bit map.  Every bit map bit is matched to one frame
in the frame table.  In order to search this bit map must acquire the frame table lock.

In the case that eviction is neccesary we pin the page to the frame
while we are evicting it, so that another user process cannot decide
to evict from that frame that we are evicting from until we are done.
We control access to this boolean using the frame table lock.

---- RATIONALE ----

>> A5: Why did you choose the data structure(s) that you did for
>> representing virtual-to-physical mappings?
We just manage all of the memory for the user pool directly, we also
leverage the pagedirectory heavily to find the virtual to kernel
mappings. We implemented no new data structure but rather decided to
use the pagedirectory to find the kernel virtual address. 


		       PAGING TO AND FROM DISK
		       =======================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.


// pagedir.h
#define PTE_AVL_ERROR 0       /* 000 */
#define PTE_AVL_SWAP (1 << 9)  /* 001 */
#define PTE_AVL_EXEC (1 << 10) /* 010 */
#define PTE_AVL_MMAP (1 << 11) /* 100 */
#define PTE_AVL_STACK (3 << 9)  /* 110 */ 

typedef uint32_t medium_t; /* used to represent one of the constants above */

The above defines define the "states" of the AVL bits of a page table entry. Since
we are using the page table as our supplemental page table as well, we needed the 
AVL bits to store the additional information.


//userprog_h
typedef uint32_t mapid_t;

//exception.h
#define MAX_ASM_PUSH 32 /* The maximum amount of data that can be pushed
						   by a single assembly instruction. This exists
						   because 80x86 tries to dereference the memory
						   before actually decrementing the stack....
						   Which is completely counter intuitive....
						   Just sayin */



---- ALGORITHMS ----

>> B2: When a frame is required but none is free, some frame must be
>> evicted.  Describe your code for choosing a frame to evict.

We use a modified version of the clock algorithm.  Because all pages
in the frame table have already been accessed (or else they would not 
have been read into the frame table), we have to zero the accesed bits
of pages some how.  

We have an evict hand and a clear hand.  The clear hand starts threshold
frames in front of the evict hand.  In every interrupt, we start clearing
accessed bits until we are threshold bits behind the evict hand.  If when
evicting the evict hand comes within threshold frames of the clear hand 
without finding  an un accessed page, we set threshold more pages as
not-accesed.  Because this happens with interrupts disabled, the
evict_hand is then guaranteed to find a non accessed page in the next
threshold pages in the frame table.  We chose a value of 1/4 the size
of the frame table for threshold.  This means that the clock hands never 
pass each other up, nor get closer than 1/4 of the size of the page table
close to each other.


>> B3: When a process P obtains a frame that was previously used by a
>> process Q, how do you adjust the page table (and any other data
>> structures) to reflect the frame Q no longer has?

Since process Q originally had the page, it must get evicted.  As soon as
the frame that Q has is chosen as the candidate for P's page, we turn off
interupts and set the Q's page as not present, and we set it's AVL_MEDIUM
and AVL_ADDR to reflect where we have moved it.  Now if Q page faults
on the page it will see the correct location of it and it will be
retrieved by the page fualt handler.


>> B4: Explain your heuristic for deciding whether a page fault for an
>> invalid virtual address should cause the stack to be extended into
>> the page that faulted.

The idea is that you must decrement your stack pointer before you place
something on the stack (with the exceptoin of pushal) so we check if their
address is between PHYS_BASE and esp (including esp but not including
PHYS_BASE).


However, because pushal dereferences memory before decrementing the stack
pointer we must also allow for stack growth if the faulting address is 
MAX_ASM_PUSH bytes below the currenty address (it is defined as 32 bytes
to allow the 4 interger registers to be pushed).

Finally, in order to avoid the stack being grown beyond it's limit, we 
make sure that growing the stack would not cause the user to exceed the 
limit of their stack size.

---- SYNCHRONIZATION ----

>> B5: Explain the basics of your VM synchronization design.  In
>> particular, explain how it prevents deadlock.  (Refer to the
>> textbook for an explanation of the necessary conditions for
>> deadlock.)
We make sure that we only acquire locks from largest to smallest scope
so that we can not have cycles in the lock graph. Because we stick with
this we know that we won't get dead lock. However our project has race
conditions that we could not figure out. 


>> B6: A page fault in process P can cause another process Q's frame
>> to be evicted.  How do you ensure that Q cannot access or modify
>> the page during the eviction process?  How do you avoid a race
>> between P evicting Q's frame and Q faulting the page back in?

Before we begin eviction we set PTE_P to not present for Q's page
table entry corresponding to the frame.  This way any accesses to 
the page after we begin eviction will page fault instead of 
accessing the frame, and it will not be able to access the page.  Once
eviction begins we pin Q's page to the frame so that neither Q nor any
other user process can attempt to reclaim the page.

If Q tries to fault the page back in before it has been written to swap,
we would have another race condition.  To handle this, before we begin writing the 
dirty page to swap we atomically set the medium of the page to be
PTE_SWAP_WAIT or PTE_MMAP_WAIT (this and the setting of the page to not
present happens in one atomic block).  When Q gets a page fault on the
page the page fault handler sees that it's status is SWAP_WAIT, so it
calls swap_read_in. Inside of swap_read_in we wait on a
condition variable and we only wake up when we have been signalled.
Everytime a read happens we broadcast on the conditional.  To signal to us
that we where in fact the process that should have been woken up, the
writer writes PTE_SWAP into our PTE_AVL bits,  and we will go back to
sleep on the conditional unless we wake up to find that we our medium has 
been set to PTE_SWAP.

>> B7: Suppose a page fault in process P causes a page to be read from
>> the file system or swap.  How do you ensure that a second process Q
>> cannot interfere by e.g. attempting to evict the frame while it is
>> still being read in?

In our frame_entry their is a bool is_pinned.  Before we begin the read
in we set this bool to true.  When we are done reading in the data from
disk we unpin page to the frame.  This way nobody can evict a page that 
is already designated as a destination for IO.


>> B8: Explain how you handle access to paged-out pages that occur
>> during system calls.  Do you use page faults to bring in pages (as
>> in user programs), or do you have a mechanism for "locking" frames
>> into physical memory, or do you use some other design?  How do you
>> gracefully handle attempted accesses to invalid virtual addresses?

We use page faults in system calls, when we are in a system call we try 
to dereference the user data through the user's pointers. Because we do
this and the address is translated through the processes pagedirectory 
it will page fault and then the normal mechanism for handling that fault
will occur. It will read in the data from wherever it is. We kill invalid
access to memory. We know what is valid and what is not because invalid 
accesses will allways have PTE_AVL_ERROR in the the AVL bits so we know 
that it is invalid.

---- RATIONALE ----

>> B9: A single lock for the whole VM system would make
>> synchronization easy, but limit parallelism.  On the other hand,
>> using many locks complicates synchronization and raises the
>> possibility for deadlock but allows for high parallelism.  Explain
>> where your design falls along this continuum and why you chose to
>> design it this way.

We are right in the middle. We have a lock for the frame table, a lock for
the swap table, and a lock for individual mmap tables that are in threads.
Because we have some locks but don't get down to the granularity of frames 
we have some possiblity of getting deadlock. Our design allows page faults
to occur and not wait on swap or mmap disk access. We also have to set the 
bits in the PTE entries synchronously by disabling interrupts until the
bits in the PTE entry are set.


			 MEMORY MAPPED FILES
			 ===================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.
 	/* A hash table that stores the necessary information to
	   map a file into the address space and to lazily load
	   the information from the file */
	struct hash mmap_table;
	mapid_t mapid_counter;

	/* As with the swap table, the mmap table can also be
	   accessed from multiple threads via eviction so it too
	   must be locked down so reading and writing to the table
	   while the owning process creates or destroyes mmaps can
	   be synchronized*/
	struct lock mmap_table_lock;

---- ALGORITHMS ----

>> C2: Describe how memory mapped files integrate into your virtual
>> memory subsystem.  Explain how the page fault and eviction
>> processes differ between swap pages and other pages.

Memory mapped files are integrated into the process. The process has its
own mmap table, a counter for map id, and a lock for the table. When a 
file is mmaped, then all of the pages that are created for that file are
put on demand and will be read in when the process faults. When a process 
faults it will always just route the fault to the appropriate place by
looking at the medium bits. We set the PTE_AVL bits to MMAP when we mmap
the file. When a page fault occurs the request for the page is routed to 
mmap_read_in which gets a free page and then puts the data into that 
page using the kernel virtual address. We do it through the kernel virtual
address so that we will not dirty the bits for the entry in the user page
directory. It is not different than the process we use for swap pages and
EXEC pages as well.

>> C3: Explain how you determine whether a new file mapping overlaps
>> any existing segment.

To do this we simply check all of the proposed entries in the page
directory to see if they are mapped, mapped being that they have their
PTE_AVL bits set. Because whenever we have valid memory we set the
AVL BITS so if they are not set this means that the mmap file will
not overlap with any other data. If we do this for every page in the 
range of the mmapped file, then the mmaped file does not overlap.
We also check that the mmap does not overlap with the max stack size
so that we know that it won't overlap then either.

---- RATIONALE ----

>> C4: Mappings created with "mmap" have similar semantics to those of
>> data demand-paged from executables, except that "mmap" mappings are
>> written back to their original files, not to swap.  This implies
>> that much of their implementation can be shared.  Explain why your
>> implementation either does or does not share much of the code for
>> the two situations.

Our impementation does not share the code because it moves the data to
different places. This is because we need to synchronize the swap table
and the mmap table k

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

Hard... We spent all week coding.... more than 40 hours on it... 

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

We would have really liked our grades back from assignment 2 because we
had to fix problems that really affected how assignment 3 worked. We had
dead lock. 

>> Any other comments?
