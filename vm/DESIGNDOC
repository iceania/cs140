          	    +---------------------------+
		    |         CS 140  		|
         	    +---------------------------+
		    |         CS 140  		|
		    | PROJECT 3: VIRTUAL MEMORY	|
		    |	   DESIGN DOCUMENT  	|
		    +---------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Sam Oluwalana <hhwr85@stanford.edu>
John-Ashton Allen <bglp05@stanford.edu>
Matt Chun-lum <mchunlum@stanford.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			PAGE TABLE MANAGEMENT
			=====================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/* Frame.h */

struct frame_table{
       struct bitmap *used_frames;   /* Bit map that tracks the used frame*/
       struct lock frame_table_lock; /* A lock on that bitmap*/
       void *base;  		     /* Base of the user memory pool*/
       uint32_t size;		     /* Size of the user memory pool in
       page size */
       struct frame _entry *entries; /* Table of frame entries */
} f_table;

struct frame_entry{	
       /* Boolean describing whether this fram is evictable */
       bool is_pinned;		     
       struct thread *cur_owner;      /* Current owner of this frame */
       void *uaddr;   /* user virtual address that is in this frame*/ 
};


/* Process.h */
	
/* The exec_info is a pointer to an array of ELF program
   header information this information is used to determine  
   where on disk the particular missing page is located.
   the information that it stores is for the entire header,
   each header is an entire segment so the size of this
   struct will be less than 5 * sizeof(exec_page_info).
   The only loadable segments right now are the code
   segment and the data segment with the global and static data.*/
   
   struct exec_page_info *exec_info;
   uint32_t num_exec_pages;

   /* A hash table that stores the necessary information to
      map a file into the address space and to lazily load
      the information from the file */
   struct hash mmap_table;
   mapid_t mapid_counter;
      
	

/* This is the struct that describes the necessary ELF
   program header information that is needed to read
   in the executable on a page fault. It does this by
   taking the faulting addresses most significant 20
   bits and seeing if it is in this particular entries
   bounds (mem_page and end_addr). Then it takes this
   offset from the faulting address and mem_page and
   adds it to the file_offset of the elf file and then
   reads in the appropriate amounts of data by calculating
   the appropriate read_bytes and zero_bytes.
   NOTE: the segment is not constrained to be only one page */

struct exec_page_info{
       /* The starting address in virtual memory of this segment*/
       uint32_t mem_page;
       
       /* The address one byte past the end of this headers segment*/
       uint32_t end_addr;

       /* The offset into the executable file for this particular
       segment*/
       uint32_t file_offset;

       /* The number of bytes to read from this segment*/
       uint32_t read_bytes;

       /* The number of bytes that are zero at the end of this
       segment. MAY BE MORE THAN ONE page worth of zero bytes*/
       uint32_t zero_bytes;  
       
       /* Whether this segment is read/write or read only*/
       bool writable;
};


---- ALGORITHMS ----

>> A2: In a few paragraphs, describe your code for locating the frame,
>> if any, that contains the data of a given page.


When a user process tries to access memory that belongs to them it's present
bit is 1 in it's page table.  In this case, the address of the frame is 
written in the PTE_ADDR bit. When we need to find the frame_entry for a user's
virtual address we simply translate the user address to a kernel address
then we use that kaddr as an offset in the kernel table. The frame_entry
contains the user address that is currently mapped to it, a variable
describing whether it is pinned or not and a condition variable that will
be used to synchronize eviction. The code for locating the frame just uses
offsets from the kaddr passed in. Our frame table implementation manages
all off the memory for a user process, any calls that would have been 
palloc_get_page(PAL_USER) now need to be frame_get_page(PAL_USER) and
calls to palloc_get_page(PAL_USER) will fail because that pool is
completely empty. 


>> A3: How does your code coordinate accessed and dirty bits between
>> kernel and user virtual addresses that alias a single frame, or
>> alternatively how do you avoid the issue?

We choose to use the user's address to dereference memory, because we only
use the user addresses to dereference memory we know that the accessed bits
and the dirty bits will be set by the processor. We also know that on
writing data out to swap and back to disk for memory mapped files we
can use the kernel virtual address in order to keep the accessed and
dirty bits for the user the same regardless of the fault that caused the
frame to be evicted. Using the kernel virtual address to access memory in
the eviction process allows us to ensure that the bits for the user's PTE
entry stay as they were. Because we manage the memory in this way we can 
guarantee that the accessed and dirty bits are always coordinated. Thank
you x86.


---- SYNCHRONIZATION ----

>> A4: When two user processes both need a new frame at the same time,
>> how are races avoided? 

When a process needs a new frame they fault, then they call
frame_get_frame with the appropriate flags. Inside frame_get_frame we have
a frame table lock must be acquired to modify the frame table so we know 
that there is no race condition between the two threads because they both.
Must acquire the same lock when they are trying to get a new frame for when
the fault and need to read in from disk/swap/mmap or when then are growing 
the stack. This simple synchronization is somewhat slow however because we
know that page faults are very common and that needing to acquire a frame 
should be fast so we did our best to only hold the lock long enough to run
the eviction algorithm and set the appropriate data in the PTE for the evicted
frame's process.

In the case that eviction is neccesary we pin the page to the frame
while we are evicting it, so that another user process cannot decide
to evict from the frame that we are currently evicting, this makes sure
that we will won't try to give the same frame to two processes at the 
same time. Access to the is_pinned boolean requires that you hold the
frame_table_lock so we know that any updates to the boolean are done 
atomically.



---- RATIONALE ----

>> A5: Why did you choose the data structure(s) that you did for
>> representing virtual-to-physical mappings?

The data structure for virtual to pysical mappings are handles by 
the PTE for that particular page. When the page is not present we
manually handle the top 20 bits of the PTE and the bits that are 
available for the OS. We know we can change the top 20 bits in the 
PTE when the page is not present because the processor only looks 
at the present bit when deciding whether it needs to invoke a page
fault. So when we need the page to fault we just set the page to be
not present and use the top 20 bits and the AVL bits to efficiently
route the page fault to find the correct data on its storage medium.

This method requires no new data structure but rather just changes 
the one that we had already to serve virtual memory better


		       PAGING TO AND FROM DISK
		       =======================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

// pagedir.h
#define PTE_AVL_ERROR 0       /* 000 */
#define PTE_AVL_SWAP (1 << 9)  /* 001 */
#define PTE_AVL_EXEC (1 << 10) /* 010 */
#define PTE_AVL_MMAP (1 << 11) /* 100 */
#define PTE_AVL_STACK (3 << 9)  /* 110 */ 

/* used to represent one of the constants above */
typedef uint32_t medium_t; 

	When the data in the PTE is not present the top 20 bits will
	refer to the virtual address of this PTE, this virtual address
	will be used as a key to locate the data that is supposed to
	be in main memory by the appropriate functions.

   31                                 12 11                PTE_P
   +----------------------------------+---+---------------------+
   |       Virtual Address            |AVL|      Flags     | 1/0|
   +----------------------------------+---+---------------------+

	How the AVL bits are used

   ERROR  - AVL BITS 000
   ------
   This should never happen because. Whenever a user is able to
   access memory we set the AVL bits to the appropriate medium
   that corresponds to where the memory belongs. 

   SWAP - AVL BITS 001
   ------
   This indicates to the page fault handler that the memory that is
   faulted on resides on the swap and that it can be recovered in a
   call to swap_read_in

   EXEC - AVL BITS 010
   ------
   This indicates to the page fault handler that the memory that it
   faulted on resides in the original file that the process was loaded
   from, and that it can be read in with a call to process_exec_read_in

   MMAP - AVL BITS 100
   ------
   This indicates to the page fault handler that the memory that it
   is looking for can be found in the original file that it mmapped
   and that its data can be found in a call to mmap_read_in

   SWAP WAIT - AVL BITS 110
   ------
   This tells the page fault handler to route this page fault to
   swap_read_in, but it also tells swap_read_in that it must make
   the requesting process to wait untill the data is completely
   transfered to disk. The top 20 bits for this condition are mostly
   ignored and only when this PTE's AVL bits get updated to PTE_SWAP
   will they continue to use the top 20 bits.

   MMAP WAIT - AVL BITS 101
   ------
   This tells the page fault handler to route this page fault to
   mmap_read_in, but also tells mmap read in that it must make the
   faulting process wait until its memory is completely written to
   the mmapped file before reading it back out. Similar to SWAP_WAIT
   The top 20 bits for this condition are mostly
   ignored and only when this PTE's AVL bits get updated to PTE_SWAP
   will they continue to use the top 20 bits.
   
   UNDEF - AVL BITS 111
   -------
   Not used in this project

/* exception.h */

/* The maximum amount of data that can be pushed
   by a single assembly instruction. This exists
   because 80x86 tries to dereference the memory
   before actually decrementing the stack....
   Which is completely counter intuitive....
   Just sayin */
#define MAX_ASM_PUSH 32 


---- ALGORITHMS ----

>> B2: When a frame is required but none is free, some frame must be
>> evicted.  Describe your code for choosing a frame to evict.

We use a modified version of the clock algorithm.  Because all pages
in the frame table have already been accessed (or else they would not 
have been read into the frame table), we have to zero the accesed bits
of pages some how.  

We have an evict hand and a clear hand.  The clear hand starts threshold
frames in front of the evict hand.  In every timer interrupt, we start clearing
accessed bits until we are threshold bits behind the evict hand.  If when
evicting the evict hand comes within threshold frames of the clear hand 
without finding  an un accessed page, we set threshold more pages as
not-accesed with the clear hand. Because this happens with interrupts 
disabled, the evict_hand is then guaranteed to find a non accessed page 
in the next threshold pages in the frame table.  We chose a value of 1/4 
the size of the frame table for threshold. This means that the clock
hands never pass each other up, nor get closer than 1/4 of the size 
of the page table to each other.


>> B3: When a process P obtains a frame that was previously used by a
>> process Q, how do you adjust the page table (and any other data
>> structures) to reflect the frame Q no longer has?

When process P obtains a frame in the eviction process it is pinned down
with the frame_table lock held. Then we disable interrupts and set the PTE
of process Q that corresponds to this frame to the correct value. If the 
page was dirty the following happens:
If the AVL bits were SWAP or EXEC we set Q's page's AVL bits to PTE_SWAP_WAIT
because it is about to be swapped out but isn't done swapping out the frame
yet, it also sets the present bit to 0 so that Q will page fault and then 
try to get the page from the swap. If the AVL bits are MMAP, they are set to
MMAP_WAIT and a similar process ensues in mmap_read_in. 
If it is clear:
If it is PTE_STACK it just clears the present bit which tells the page
fault handler to just grant the process a new ZEROed out page. This is
because if the data is on the stack and has not been accessed then it 
was just a zero page anyway and we can just yank the frame fro Q. 
If it is PTE_EXEC then we set up a demand page which tells the page fault
handler to read this file from its original location. 
If it is PTE_MMAP we also define a demand page which tells the page fault
handler to read this page in from the orginal mmapped file.

pagedir_setup_demand_page is the heart of the if/else tree it disables
interrupts sets the present bit to 0, set the writable bit to what is 
passed in, sets the upper 20 bits to the appropriate user virtual address
and sets the AVL bits to the given medium. 

After the bits are set Q no longer has the frame. On pagedir destroy we
check if the frame is pinned, if it isn't pinned we will set it to not 
pinned and set the user address and current owner to NULL. Then set the 
frame table bitmap to show that it is free to be handed out. 

That is all that is needed to update Q and specify where it's data is.


>> B4: Explain your heuristic for deciding whether a page fault for an
>> invalid virtual address should cause the stack to be extended into
>> the page that faulted.

The idea is that you must decrement your stack pointer before you place
something on the stack, however x86 decides to only increment ESP after
the move has been made, for this reason we need to take this into account.
Our heuristic goes as follows: we define the valid stack segment to be 
addresses between 0xc0000000 and 0xc0000000 - max_stack_size. A constant
that defaults to 8 mb but can be changed at the command line by specifying
--stack=X. If it is in this region it may be valid so next we check to see
if the address handed in is above esp, but we can't check this directly we
must also subtract from esp the maximum size of an assembly push (pushal 
which pushes all of the registers at once). If these conditions pass we
then set all of the pages in the processes page directory that all indicate
that the memory is PTE_STACK and not present, this makes sure that if the 
process decides to allocate alot of space that only when it tries to 
actually use that data will it actually have frames allocated for it. 

---- SYNCHRONIZATION ----

>> B5: Explain the basics of your VM synchronization design.  In
>> particular, explain how it prevents deadlock.  (Refer to the
>> textbook for an explanation of the necessary conditions for
>> deadlock.)


We try to only acquire at most 2 locks at any given time. Because we 
only acquire at most 2 locks at the same time we can easily draw out 
the dependency graphs for our code. We also make sure that, when possible,
we acquire our locks from largest to smallest scope, this also reduces the 
chance that we have deadlock in the function; When we start thinking
about locks we can easily write out all the different possible combinations
of locks and see which combinations of acquires will cause dead lock and
evict them, just like we evict frames lol. 


>> B6: A page fault in process P can cause another process Q's frame
>> to be evicted.  How do you ensure that Q cannot access or modify
>> the page during the eviction process?  How do you avoid a race
>> between P evicting Q's frame and Q faulting the page back in?


Before we begin eviction we set PTE_P to not present for Q's page
table entry corresponding to the frame.  This way any accesses to 
the page after we begin eviction will page fault instead of 
accessing the frame, and it will not be able to access the page.  Once
eviction begins we pin Q's page to the frame so that neither Q nor any
other user process can attempt to reclaim the page until it is unpined.

If Q tries to fault the page back in before it has been written to swap,
we would have another race condition.  To handle this, before we begin writing the 
dirty page to swap we atomically set the medium of the page to be
PTE_SWAP_WAIT or PTE_MMAP_WAIT (this and the setting of the page to not
present happens in one atomic block).  When Q gets a page fault on the
page the page fault handler sees that it's status is SWAP_WAIT, so it
calls swap_read_in. Inside of swap_read_in we wait on a
condition variable and we only wake up when we have been signalled.
Everytime a read happens we broadcast on the conditional.  To signal to us
that we where in fact the process that should have been woken up, the
writer writes PTE_SWAP into our PTE_AVL bits,  and we will go back to
sleep on the conditional unless we wake up to find that we our medium has 
been set to PTE_SWAP.


>> B7: Suppose a page fault in process P causes a page to be read from
>> the file system or swap.  How do you ensure that a second process Q
>> cannot interfere by e.g. attempting to evict the frame while it is
>> still being read in?


In our frame_entry their is a bool is_pinned.  Before we begin the read
in we set this bool to true.  When we are done reading in the data from
disk we unpin the frame. This way nobody can evict a page that 
is already designated as a destination for IO. We ensure that the pinned
variable is only changed to false by the thread that just recieved the 
page from frame_get_frame. Because we only unpin this when we are done
reading our data into it for the case of IO, and because a frame that is
pinned will not be marked for eviction, we can guarantee that our frame
will stay valid untill all of the data is written to the frame in either
the swap code, exec code, or mmap code. 


>> B8: Explain how you handle access to paged-out pages that occur
>> during system calls.  Do you use page faults to bring in pages (as
>> in user programs), or do you have a mechanism for "locking" frames
>> into physical memory, or do you use some other design?  How do you
>> gracefully handle attempted accesses to invalid virtual addresses?


We use page faults in system calls, when we are in a system call we try 
to dereference the user data through the user's pointers before even 
working with the data, because we kill the process if the page fault 
occurs in bad memory we know that we will either exit or have valid 
memory when we start executing the system call. This error checking 
leverages the processes page directory which will correctly identify
the validity of the fault through its normal mechanism for handling that.
It will read in the data from wherever it is. We kill for invalid
accesses to memory. If the memory is valid we just run the system call
using the user address as normal. This may or may not refault pages in 
from swap or mmap but it is transparent to the system call handlers.


---- RATIONALE ----

>> B9: A single lock for the whole VM system would make
>> synchronization easy, but limit parallelism.  On the other hand,
>> using many locks complicates synchronization and raises the
>> possibility for deadlock but allows for high parallelism.  Explain
>> where your design falls along this continuum and why you chose to
>> design it this way.

We are right in the middle. We have a lock for the frame table, a lock for
the swap table, and a lock for individual mmap tables that are in processes.
Because we have some locks but don't get down to the granularity of frames 
we have some possiblity of getting deadlock. Our design is simple enough 
that the likeliehood of that happenig is fairly low. However some 
parallelism is sacrificed as a cost. We know that the frame_table_lock needs
to be held for as short as possible in order to get the maximum benifit of
parallelism so we try our hardest to reduce the amount of code that goes
on inside that lock. The swap lock we are more liberal with because we know
that the time it takes to put something on the swap is what will dominate
so we include much more code while we have the swap lock enabled, the same
is true for mmap_locks as well. Because all the IO occurs outside the frame
lock our system may be slow but it still runs at memory speed given an 
appropriate eviction algorithm which can be specified by changing the 
implementation of the choose_next_frame_evict_x.

			 MEMORY MAPPED FILES
			 ===================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.


/*userprog_h*/

typedef uint32_t mapid_t;

 	/* A hash table that stores the necessary information to
	   map a file into the address space and to lazily load
	   the information from the file */
	struct hash mmap_table;
	mapid_t mapid_counter;

	/* As with the swap table, the mmap table can also be
	   accessed from multiple threads via eviction so it too
	   must be locked down so reading and writing to the table
	   while the owning process creates or destroyes mmaps can
	   be synchronized*/
	struct lock mmap_table_lock;

/* Process.h*/
	
	/* The entry in the mmap table */
struct mmap_hash_entry{
	mapid_t mmap_id;     	/* Key into the hash table*/
	uint32_t begin_addr;	/* start address of this mmapping*/
	
	/* While we can calculate this from the filesize accessing the
	disk In any way is too slow so just keep it stored in memory*/
	uint32_t end_addr;
	
	int fd;		     /* FD for this mapping*/
	uint32_t num_pages;  /* Number of pages so I don't have to calculate*/
	struct hash_elem elem;  /* hash elem*/
};


---- ALGORITHMS ----

>> C2: Describe how memory mapped files integrate into your virtual
>> memory subsystem.  Explain how the page fault and eviction
>> processes differ between swap pages and other pages.


Memory mapped files are integrated into the process. The process has its
own mmap table, a counter for map id, and a lock for the table. When a 
file is mmaped, then all of the pages that are created for that file are
put on demand and will be read in when the process faults. When a process 
faults it will always just route the fault to the appropriate place by
looking at the medium bits. Because for all pages mapped to mmap we put
PTE_MMAP we know that page faults will be mapped to mmap_read_in. In this
function we acquire the filesystem lock and read in the file. Because we
know that the only thread that can read in this file is our own and that 
the only race condition that can happen is between the insertion and deletion
of mmap entries for the process. To solve this we make sure that when the 
process exits it releases all of its mmap entries holding its mmap lock, 
while it is deleting these entries it also waits for PTE_MMAP_WAIT to be 
PTE_MMAP for any files before continuing writing its dirty pages to disk. 
Because it needs to wait for this condition, and that if a frame is on 
disk for mmap that it will to be writen out only once. Using this 
method we avoid race conditions. And ensure that all data is written
out when the process exits.

>> C3: Explain how you determine whether a new file mapping overlaps
>> any existing segment.

To do this we simply check all of the proposed entries in the page
directory to see if they are mapped. Because whenever we put any 
memory in the virtual address space of this process we also set the
PTE_AVL bits to where this memory belongs / where it came from. If 
we have yet to set it, the PTE_AVL bits will be set to 0 by the 
default meaning that when we get the medium it will be PTE_AVL_ERROR
and we know that it is unmapped. So we just check every page in the
processes page dir and if they are all PTE_AVL_ERROR we can just mmap
the file, otherwise we will just make them fail.


---- RATIONALE ----

>> C4: Mappings created with "mmap" have similar semantics to those of
>> data demand-paged from executables, except that "mmap" mappings are
>> written back to their original files, not to swap.  This implies
>> that much of their implementation can be shared.  Explain why your
>> implementation either does or does not share much of the code for
>> the two situations.


We did keep alot of the code about how to handle the paging in and out
of the mmap files the same as alot of everything else. we even use the
same function pagedir_setup_demand_page to set up and route the pages
in the frame table. This abstraction is key to our implementation of 
virtual memory. When we actually read in or write out mmap data we 
do have different functions however because we handle the data differently
alot of code is shared between the implementations but because they are 
different enough in their behavior we seperated them out. Also they
acquire much different locks because we have a global swap device but
mmap files are only stored per process. Thats another reason why we 
choose to seperate the implementations. 


			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?


Hard... We spent all week coding.... more than 40 hours on it... 

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

We would have really liked our grades back from assignment 2 because we
found race conditions and deadlock that weren't evident when we submitted
project 2. Wish we would have known about it cause we spent alot of time 
debuging it.


>> Any other comments?
